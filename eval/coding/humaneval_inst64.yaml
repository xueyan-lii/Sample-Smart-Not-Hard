task: humaneval_inst64
dataset_path: openai/openai_humaneval
unsafe_code: true
output_type: generate_until
test_split: test
#doc_to_text: "Write a solution to the following problem and make sure that it passes the tests:\n```python\n{{ prompt }}\n```\n"
#gen_prefix: "Here is the completed function:\n```python\n{{ prompt }}\n"
doc_to_text: "{{prompt}}"
doc_to_target: "{{test}}\ncheck({{entry_point}})"
metric_list:
  - metric: !function humaneval_utils.pass_at_k
    aggregation: mean
    higher_is_better: true
    k: [1,4,8,16,32]
generation_kwargs:
  until:
    - "\nclass"
    - "\ndef"
    - "\n#"
    - "\nif"
    - "\nprint"
  max_gen_toks: 1024
  do_sample: True
  temperature: 0.6
#  top_p: 0.95
repeats: 32
num_fewshot: 0
filter_list:
  - name: "create_test"
    filter:
      - function: "custom"
        filter_fn: !function humaneval_utils.build_predictions
metadata:
  version: 1.0